{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809e5203-2afe-449a-9acc-50b546967ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/pmishra/.local/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352d338d-e2cf-4d61-bf32-55dddd14a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c12749-7a75-4355-ac57-60420cf8c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# # Function to capture photos for training data\n",
    "# def capture_photos(subject_name, output_folder):\n",
    "#     # Initialize camera\n",
    "#     camera = cv2.VideoCapture(0)\n",
    "#     cv2.namedWindow(\"Capture Photos\")\n",
    "    \n",
    "#     # Create directory if it doesn't exist\n",
    "#     output_path = os.path.join(output_folder, subject_name)\n",
    "#     os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "#     # Capture photos\n",
    "#     count = 0\n",
    "#     while True:\n",
    "#         ret, frame = camera.read()\n",
    "#         cv2.imshow(\"Capture Photos\", frame)\n",
    "        \n",
    "#         # Press 'q' to quit capturing\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "        \n",
    "#         # Press 's' to save the captured photo\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "#             count += 1\n",
    "#             img_name = os.path.join(output_path, \"{}.jpg\".format(count))\n",
    "#             cv2.imwrite(img_name, frame)\n",
    "#             print(\"{} saved!\".format(img_name))  # Print confirmation message\n",
    "#             # Delay to ensure the message is displayed before closing window\n",
    "#             cv2.waitKey(1000)  \n",
    "#             # Delay to avoid capturing multiple images with a single press\n",
    "#             while cv2.waitKey(1) & 0xFF == ord('s'):  \n",
    "#                 pass\n",
    "    \n",
    "#     camera.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Example usage:\n",
    "# subject_name = input(\"Enter subject name: \")\n",
    "# output_folder = \"/home/pmishra/Desktop/Projects/Github Projects/Face_Detect/Data\"\n",
    "# capture_photos(subject_name, output_folder)\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to detect face and save photos\n",
    "def capture_photos(subject_name, output_folder):\n",
    "    # Initialize camera\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Capture Photos\")\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    output_path = os.path.join(output_folder, subject_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Initialize face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Capture photos\n",
    "    count = 0\n",
    "    while count < 50:  # Capture up to 50 photos\n",
    "        ret, frame = camera.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from camera!\")\n",
    "            break\n",
    "        \n",
    "        # Convert frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        \n",
    "        # Draw rectangles around detected faces and save photos on 's' key press\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                count += 1\n",
    "                img_name = os.path.join(output_path, \"{}.jpg\".format(count))\n",
    "                cv2.imwrite(img_name, frame)\n",
    "                print(\"{} saved!\".format(img_name))  # Print confirmation message\n",
    "        \n",
    "        # Display frame with rectangles drawn around faces\n",
    "        cv2.imshow(\"Capture Photos\", frame)\n",
    "        \n",
    "        # Press 'q' to quit capturing\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release camera and close OpenCV windows\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "subject_name = input(\"Enter subject name: \")\n",
    "output_folder = \"/home/pmishra/Desktop/Projects/Github Projects/Face_Detect/Data\"\n",
    "capture_photos(subject_name, output_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a700d17-9282-48c2-a081-51b4218871a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare training data\n",
    "def prepare_training_data(data_folder_path):\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    faces = []\n",
    "    labels = []\n",
    "    \n",
    "    for dir_name in dirs:\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        subject_dir_path = os.path.join(data_folder_path, dir_name)\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        for image_name in subject_images_names:\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue\n",
    "            image_path = os.path.join(subject_dir_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            if face is not None:\n",
    "                faces.append(face)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return faces, labels\n",
    "\n",
    "# Example usage after capturing photos:\n",
    "data_folder_path = \"/home/pmishra/Desktop/Projects/Github Projects/Face_Detect/Data\"\n",
    "faces, labels = prepare_training_data(data_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88b743-fae5-4738-b31b-e3cbdbffdaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict faces in test images# Function to predict faces in test images\n",
    "def predict(test_img_path, output_folder):\n",
    "    img = cv2.imread(test_img_path)\n",
    "    predicted_img = img.copy()\n",
    "    face, rect = detect_face(predicted_img)\n",
    "    label, confidence = face_recognizer.predict(face)\n",
    "    label_text = subjects[label]\n",
    "    \n",
    "    draw_rectangle(predicted_img, rect)\n",
    "    draw_text(predicted_img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "    # Save recognition output\n",
    "    output_path = os.path.join(output_folder, \"output.jpg\")\n",
    "    cv2.imwrite(output_path, predicted_img)\n",
    "    \n",
    "    return predicted_img\n",
    "\n",
    "# Example usage:\n",
    "test_img1_path = \"test-data/test1.jpg\"\n",
    "output_folder = \"/home/pmishra/Desktop/Projects/Github Projects/Face_Detect/Output\"\n",
    "predicted_img1 = predict(test_img1_path, output_folder)\n",
    "\n",
    "def predict(test_img_path, output_folder):\n",
    "    img = cv2.imread(test_img_path)\n",
    "    predicted_img = img.copy()\n",
    "    face, rect = detect_face(predicted_img)\n",
    "    label, confidence = face_recognizer.predict(face)\n",
    "    label_text = subjects[label]\n",
    "    \n",
    "    draw_rectangle(predicted_img, rect)\n",
    "    draw_text(predicted_img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "    # Save recognition output\n",
    "    output_path = os.path.join(output_folder, \"output.jpg\")\n",
    "    cv2.imwrite(output_path, predicted_img)\n",
    "    \n",
    "    return predicted_img\n",
    "\n",
    "# Example usage:\n",
    "test_img1_path = \"test-data/test1.jpg\"\n",
    "output_folder = \"/home/pmishra/Desktop/Projects/Github Projects/Face_Detect/Output\"\n",
    "predicted_img1 = predict(test_img1_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203336e-ee6d-4e2b-bf40-44bd1db700e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a2b27-769b-4a51-bb90-26adf1efc93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2af3ba-b116-4cd1-99f9-78a909b39abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ea247-ba5d-4d42-b5d5-f16982ca135d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b45d6-a59e-4079-84f7-3ecd0f8b77fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55391d65-9246-4748-beb8-0637f98646ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect face using OpenCV\n",
    "def detect_face(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    (x, y, w, h) = faces[0]\n",
    "    return gray[y:y+w, x:x+h], faces[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a486e3-2ae1-4402-936a-04a0891ed519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare training data\n",
    "def prepare_training_data(data_folder_path):\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    faces = []\n",
    "    labels = []\n",
    "    \n",
    "    for dir_name in dirs:\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        subject_dir_path = os.path.join(data_folder_path, dir_name)\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        for image_name in subject_images_names:\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue\n",
    "            image_path = os.path.join(subject_dir_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            if face is not None:\n",
    "                faces.append(face)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return faces, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d14b2-532e-4b36-81bb-d755e6cdc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare training data\n",
    "print(\"Preparing data...\")\n",
    "faces, labels = prepare_training_data(\"training-data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559f955-7609-4353-a9d2-9d1898bdd985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LBPH Face Recognizer\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996e566-f863-47bb-9775-8f8025e8a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the face recognizer\n",
    "face_recognizer.train(faces, np.array(labels))\n",
    "print(\"Data prepared and face recognizer trained successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f5544-f230-4189-87f4-d79373b234ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw rectangle around face\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3297d-3470-4679-86a5-59725902b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw text on image\n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a3a0a-3ce5-47d3-adb8-c2d52bfab328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict faces in test images\n",
    "def predict(test_img_path):\n",
    "    img = cv2.imread(test_img_path)\n",
    "    predicted_img = img.copy()\n",
    "    face, rect = detect_face(predicted_img)\n",
    "    label, confidence = face_recognizer.predict(face)\n",
    "    label_text = subjects[label]\n",
    "    \n",
    "    draw_rectangle(predicted_img, rect)\n",
    "    draw_text(predicted_img, label_text, rect[0], rect[1]-5)\n",
    "    return predicted_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f792127-f8ec-4be8-820d-9af98cd5e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform prediction on test images\n",
    "test_img1_path = \"test-data/test1.jpg\"\n",
    "test_img2_path = \"test-data/test2.jpg\"\n",
    "\n",
    "predicted_img1 = predict(test_img1_path)\n",
    "predicted_img2 = predict(test_img2_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7b1ea-701e-489a-87d9-0056e6b17202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display predicted images\n",
    "subjects = [\"\", \"manusudhan\", \"gagan\"]  # Assuming labels start from 1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(cv2.cvtColor(predicted_img1, cv2.COLOR_BGR2RGB))\n",
    "ax1.axis('off')\n",
    "ax1.set_title(subjects[1])\n",
    "ax2.imshow(cv2.cvtColor(predicted_img2, cv2.COLOR_BGR2RGB))\n",
    "ax2.axis('off')\n",
    "ax2.set_title(subjects[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70681a39-c17e-4425-a9ee-8d958745d384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc37b1a-05c6-40a1-9f55-8759b3c374f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
